{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b34fe0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from potentiel_solaire.database.queries import get_high_priority_schools, get_regions\n",
    "from potentiel_solaire.features.roof_attributes import segmentation_toits, recuperation_mns\n",
    "\n",
    "from potentiel_solaire.constants import RESULTS_FOLDER, DEFAULT_CRS\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64abd285",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7e808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SRS_METERS = 'EPSG:2154'  # used for WMS requests\n",
    "DEFAULT_CRS_METERS = int(DEFAULT_SRS_METERS.split(\":\")[1])\n",
    "\n",
    "# Overwrite the default projections with specific ones for DROMS\n",
    "SRS_BY_REGION = {\n",
    "    \"01\": \"EPSG:5490\",  # Guadeloupe\n",
    "    \"02\": \"EPSG:5490\",  # Martinique\n",
    "    # \"03\": \"EPSG:2972\", TODO: find correct srs for Guyane for WMS requests\n",
    "    \"04\": \"EPSG:2975\",  # La Réunion\n",
    "    \"06\": \"EPSG:4471\",  # Mayotte\n",
    "}\n",
    "\n",
    "MIN_SEGMENT_SURFACE = 2\n",
    "\n",
    "OUPUT_CSV_PATH = RESULTS_FOLDER / \"roof_segments_with_mns.csv\"\n",
    "ERRORS_CSV_PATH = RESULTS_FOLDER / \"roof_segments_errors.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fd8c26",
   "metadata": {},
   "source": [
    "## Bâtiments des écoles prioritaires pour Greenpeace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98cd2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "priotirized_schools = get_high_priority_schools()\n",
    "\n",
    "priotirized_schools_buildings = []\n",
    "for code_departement in priotirized_schools[\"code_departement\"].unique():\n",
    "    # Read results for the current department\n",
    "    path_results = RESULTS_FOLDER / f\"D{code_departement}_pipeline_results.gpkg\"\n",
    "    schools_buildings_dep = gpd.read_file(\n",
    "        path_results, layer=\"solar_potential_of_schools_buildings\"\n",
    "    ).to_crs(DEFAULT_CRS_METERS)[[\n",
    "        \"cleabs_bat\", \n",
    "        \"identifiant_de_l_etablissement\", \n",
    "        \"surface_totale_au_sol\", \n",
    "        \"surface_utile\", \n",
    "        \"potentiel_solaire\",\n",
    "        \"geometry\"\n",
    "    ]]\n",
    "\n",
    "    # Get priotirized schools for the current department\n",
    "    priotirized_schools_dep = priotirized_schools[priotirized_schools[\"code_departement\"] == code_departement]\n",
    "\n",
    "    # Filter priotirized schools buildings for the current department\n",
    "    priotirized_schools_buildings_dep = schools_buildings_dep.merge(\n",
    "        priotirized_schools_dep[[\"identifiant_de_l_etablissement\", \"code_region\", \"code_departement\"]],\n",
    "        on=\"identifiant_de_l_etablissement\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    # Append to the list\n",
    "    priotirized_schools_buildings.append(priotirized_schools_buildings_dep)\n",
    "\n",
    "\n",
    "# Concatenate all departements geodataframes\n",
    "priotirized_schools_buildings = gpd.GeoDataFrame(\n",
    "    pd.concat(priotirized_schools_buildings, ignore_index=True), \n",
    "    crs=DEFAULT_CRS_METERS\n",
    ")\n",
    "\n",
    "# Save the results\n",
    "output_path = RESULTS_FOLDER / \"priotirized_schools_buildings.gpkg\"\n",
    "priotirized_schools_buildings.to_file(\n",
    "    output_path, \n",
    "    layer=\"results_with_simplified_method\",\n",
    "    driver=\"GPKG\"\n",
    ")\n",
    "\n",
    "nb_priotirized_schools = len(priotirized_schools_buildings[\"identifiant_de_l_etablissement\"].unique())\n",
    "nb_priotirized_schools_buildings = len(priotirized_schools_buildings)\n",
    "print(f\"Nombre d'établissements scolaires prioritaires : {nb_priotirized_schools}\")\n",
    "print(f\"Nombre de bâtiments d'établissements scolaires prioritaires : {nb_priotirized_schools_buildings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84894a2",
   "metadata": {},
   "source": [
    "## Determination des batiments pour le calcul de segmentation des toits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f71daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously computed buildings \n",
    "computed_buildings = pd.read_csv(OUPUT_CSV_PATH, dtype={\"cleabs_bat\": str})[\"cleabs_bat\"].unique()\n",
    "nb_computed_buildings = len(computed_buildings)\n",
    "ratio_computed_buildings = nb_computed_buildings / nb_priotirized_schools_buildings\n",
    "print(f\"Nombre de bâtiments déjà calculés : {nb_computed_buildings} ({ratio_computed_buildings:.2%})\")\n",
    "\n",
    "# Filtre regions where we can retrieve MNS\n",
    "selected_regions = get_regions()\n",
    "selected_regions.remove(\"03\")  # Exclude Guyane as WMS requests will fail\n",
    "\n",
    "# Filter buildings selected for computation \n",
    "priotirized_schools_buildings_to_compute = priotirized_schools_buildings[\n",
    "    (priotirized_schools_buildings[\"code_region\"].isin(selected_regions)) &\n",
    "    (~priotirized_schools_buildings[\"cleabs_bat\"].isin(computed_buildings))\n",
    "].reset_index().copy()\n",
    "\n",
    "nb_buildings_to_compute = len(priotirized_schools_buildings_to_compute)\n",
    "print(f\"Nombre de bâtiments d'établissements scolaires prioritaires à calculer : {nb_buildings_to_compute}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b489e",
   "metadata": {},
   "source": [
    "## Calculs en utilisant la segmentation des toits via les MNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roof_attributes_with_mns(\n",
    "    building: gpd.GeoDataFrame, \n",
    "    min_surface : float, \n",
    "    crs: int,\n",
    "    srs: str, \n",
    "    cleabs_bat: str,\n",
    "    identifiant_de_l_etablissement: str,\n",
    "    code_departement: str,\n",
    "    code_region: str,\n",
    "    longitude: float,\n",
    "    latitude: float,\n",
    "):      \n",
    "    building = building.to_crs(crs)\n",
    "\n",
    "    # Compute roof attributes using MNS\n",
    "    result = segmentation_toits(\n",
    "        recuperation_mns(\n",
    "            zone_of_interest=building, \n",
    "            srs=srs\n",
    "        ), \n",
    "        min_surface=min_surface\n",
    "    )\n",
    "\n",
    "    # Add building context\n",
    "    result[\"cleabs_bat\"] = cleabs_bat\n",
    "    result[\"identifiant_de_l_etablissement\"] = identifiant_de_l_etablissement\n",
    "    result[\"code_departement\"] = code_departement\n",
    "    result[\"code_region\"] = code_region\n",
    "    result[\"longitude\"] = longitude\n",
    "    result[\"latitude\"] = latitude\n",
    "\n",
    "    # Bins of 5 degrees for slope and azimuth\n",
    "    result[\"slope_bin_min\"] = ((result[\"slope\"] // 5) * 5).astype(int)\n",
    "    result[\"slope_bin_max\"] = result[\"slope_bin_min\"] + 5\n",
    "    result[\"azimut_bin_min\"] = ((result[\"azimut\"] // 5) * 5).astype(int)\n",
    "    result[\"azimut_bin_max\"] = result[\"azimut_bin_min\"] + 5\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb62bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cleabs_bat in tqdm(priotirized_schools_buildings_to_compute[\"cleabs_bat\"].unique()):\n",
    "    building = priotirized_schools_buildings_to_compute[priotirized_schools_buildings_to_compute[\"cleabs_bat\"] == cleabs_bat].copy()\n",
    "\n",
    "    assert len(building) == 1, f\"Multiple buildings found for cleabs_bat {cleabs_bat}\"\n",
    "\n",
    "    cleabs_bat = building[\"cleabs_bat\"].values[0]\n",
    "    identifiant_de_l_etablissement = building[\"identifiant_de_l_etablissement\"].values[0]\n",
    "    code_departement = building[\"code_departement\"].values[0]\n",
    "    code_region = building[\"code_region\"].values[0]\n",
    "    building_centroid = building.to_crs(DEFAULT_CRS).geometry.centroid\n",
    "    longitude = building_centroid.x.values[0]\n",
    "    latitude = building_centroid.y.values[0]\n",
    "\n",
    "    srs = SRS_BY_REGION.get(code_region, DEFAULT_SRS_METERS)\n",
    "    crs = int(srs.split(\":\")[1])\n",
    "\n",
    "    try: \n",
    "        building_result = compute_roof_attributes_with_mns(\n",
    "            building=building,\n",
    "            min_surface=MIN_SEGMENT_SURFACE,\n",
    "            crs=crs,\n",
    "            srs=srs,\n",
    "            cleabs_bat=cleabs_bat,\n",
    "            identifiant_de_l_etablissement=identifiant_de_l_etablissement,\n",
    "            code_departement=code_departement,\n",
    "            code_region=code_region,\n",
    "            longitude=longitude,\n",
    "            latitude=latitude,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing building {cleabs_bat}: {e}\")\n",
    "        # Save the error in a CSV file\n",
    "        error_data = {\n",
    "            \"cleabs_bat\": cleabs_bat,\n",
    "            \"identifiant_de_l_etablissement\": identifiant_de_l_etablissement,\n",
    "            \"code_departement\": code_departement,\n",
    "            \"code_region\": code_region,\n",
    "            \"longitude\": longitude,\n",
    "            \"latitude\": latitude,\n",
    "            \"geometry\": building.geometry.values[0].wkt,\n",
    "            \"area\": building.geometry.area.values[0],\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "        pd.DataFrame([error_data]).to_csv(ERRORS_CSV_PATH, mode='a', header=not ERRORS_CSV_PATH.exists(), index=False)\n",
    "        continue\n",
    "\n",
    "    if not building_result.empty:\n",
    "        # append the result in csv\n",
    "        building_result.to_csv(OUPUT_CSV_PATH, mode='a', header=not OUPUT_CSV_PATH.exists(), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "potentiel-solaire-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
